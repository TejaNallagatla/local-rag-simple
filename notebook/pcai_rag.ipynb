{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCAI PDF RAG System\n",
    "\n",
    "## Complete Implementation of 5 Required Components\n",
    "\n",
    "This notebook demonstrates a working Retrieval-Augmented Generation system using PDF File\n",
    "\n",
    "**Components Implemented:**\n",
    "1. Knowledge Base (PDF)\n",
    "2. Semantic Layer (sentence-transformers)\n",
    "3. Retrieval System (FAISS)\n",
    "4. Augmentation (context enrichment)\n",
    "5. Generation (answer synthesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import All Components\n",
    "\n",
    "Run this cell first to load all modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All components imported successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nallagat/playground/at-2/rag-venv/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Import our 5 components\n",
    "from knowledge_base import KnowledgeBase\n",
    "from semantic_layer import SemanticLayer\n",
    "from retrieval_system import RetrievalSystem\n",
    "from augmentation import Augmentation\n",
    "from generation import Generation\n",
    "print(\"âœ… All components imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component 1: Knowledge Base\n",
    "\n",
    "Load PCAI dataset from pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“š Knowledge Base initialized\n",
      "\n",
      "ðŸ“¥ Loading PDF: data/hpe-pcai.pdf\n",
      "âœ… Loaded 24 pages from PDF\n",
      "âœ… Created 57 text chunks\n",
      "\n",
      "ðŸ“Š Knowledge Base:\n",
      "   Pages: 24\n",
      "   Chunks: 57\n",
      "   Source: data/hpe-pcai.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize KB with PDF and chunk settings\n",
    "kb = KnowledgeBase(pdf_path=\"data/hpe-pcai.pdf\", chunk_size=200, chunk_overlap=50)\n",
    "\n",
    "# Load PDF pages\n",
    "documents = kb.load_pdf_data()\n",
    "\n",
    "# Create sentence-preserving chunks\n",
    "chunks = kb.create_chunks()\n",
    "\n",
    "# Inspect stats\n",
    "stats = kb.get_stats()\n",
    "stats = kb.get_stats()\n",
    "print(f\"\\nðŸ“Š Knowledge Base:\")\n",
    "print(f\"   Pages: {stats['total_pages']}\")\n",
    "print(f\"   Chunks: {stats['total_chunks']}\")\n",
    "print(f\"   Source: {stats['source']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component 2: Semantic Layer\n",
    "\n",
    "Convert text to numerical embeddings for semantic comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Semantic Layer\n",
    "semantic = SemanticLayer()\n",
    "\n",
    "# Encode all documents to embeddings\n",
    "document_embeddings = semantic.encode_documents(documents)\n",
    "\n",
    "print(f\"\\nðŸ“Š Embedding Statistics:\")\n",
    "print(f\"   Shape: {document_embeddings.shape}\")\n",
    "print(f\"   Meaning: {document_embeddings.shape[0]} documents\")\n",
    "print(f\"   Each represented by {document_embeddings.shape[1]} numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  COMPONENT 2: Semantic Layer initializing...\n",
      "   Loading model: all-MiniLM-L6-v2\n",
      "   (First run downloads 22MB - takes 30 seconds)\n",
      "âœ… Model loaded! Embeddings dimension: 384\n",
      "\n",
      "ðŸ”„ Encoding 57 document chunks to embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nallagat/playground/at-2/rag-venv/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a595ba6f05cf4a94981b7ac6c47dc0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings created: (57, 384)\n",
      "\n",
      "ðŸ“„ Random preview of 5 chunks with embeddings:\n",
      "\n",
      "--- Sample 1 (Index 32) ---\n",
      "Page: 12\n",
      "Text (first 200 chars): supply branch circuits The total system AC load does not exceed 80% of the branch circuit's rated AC For installations using a UPS, the load must not exceed 80% of the UPS's marked electrical current ...\n",
      "Embedding shape: (384,)\n",
      "Embedding sample (first 10 values): [ 0.01328968  0.03771245 -0.07328703 -0.05400196 -0.03626148  0.0047138\n",
      "  0.00410422  0.09722557  0.02806317  0.05871234]\n",
      "----------------------------------------------------------------------\n",
      "--- Sample 2 (Index 36) ---\n",
      "Page: 15\n",
      "Text (first 200 chars): Network bandwidth and software updates Network bandwidth and software updates HPE Private Cloud AI requires a sustained Internet connection of at least 100 Mbps to ensure that software updates finish ...\n",
      "Embedding shape: (384,)\n",
      "Embedding sample (first 10 values): [-0.01714158 -0.03546501  0.05789873 -0.08162022  0.03032633 -0.01002431\n",
      " -0.00985314  0.01932574 -0.01711247  0.03337695]\n",
      "----------------------------------------------------------------------\n",
      "--- Sample 3 (Index 42) ---\n",
      "Page: 17\n",
      "Text (first 200 chars): In these scenarios, new workload creation will be blocked until a valid license is restored. End user license agreement End user license agreement For information about the end user license agreement ...\n",
      "Embedding shape: (384,)\n",
      "Embedding sample (first 10 values): [-0.11683674 -0.04737226  0.0214255  -0.06360027 -0.03262044  0.02048146\n",
      " -0.00521032 -0.07236074  0.02930319 -0.01958086]\n",
      "----------------------------------------------------------------------\n",
      "--- Sample 4 (Index 20) ---\n",
      "Page: 8\n",
      "Text (first 200 chars): NVIDIA Blueprints NVIDIA Blueprints are predefined, customizable AI workflows from NVIDIA that can assist you in creating and deploying generative AI applications. Blueprints are designed for you to d...\n",
      "Embedding shape: (384,)\n",
      "Embedding sample (first 10 values): [-0.12137455 -0.00560955 -0.01764018 -0.02416047  0.04519631  0.01617542\n",
      " -0.05777144  0.04790365 -0.04138054 -0.05592494]\n",
      "----------------------------------------------------------------------\n",
      "--- Sample 5 (Index 48) ---\n",
      "Page: 19\n",
      "Text (first 200 chars): TB (adding 1xCNode and 2x JBOFs) 217 TB to 529 TB (adding 1xCNode and 3x JBOFs) 217 TB to 1088 TB (adding 1xCNode and 7x JBOFs) HPE HPE GreenLake for File GreenLake for File Storage (Standard Storage ...\n",
      "Embedding shape: (384,)\n",
      "Embedding sample (first 10 values): [-0.03240145 -0.06121505 -0.06994621 -0.03559827  0.021454    0.00223989\n",
      " -0.00969227  0.07949185 -0.06802074  0.04840973]\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Random Preview: Chunks & Embeddings\n",
    "# =========================\n",
    "\n",
    "# Number of random samples to preview\n",
    "N = 5\n",
    "\n",
    "# Ensure embeddings exist\n",
    "try:\n",
    "    document_embeddings\n",
    "except NameError:\n",
    "    # Encode chunks if not done yet\n",
    "    semantic = SemanticLayer()\n",
    "    document_embeddings = semantic.encode_documents(kb.chunks)\n",
    "\n",
    "# Random indices\n",
    "random_indices = random.sample(range(len(kb.chunks)), min(N, len(kb.chunks)))\n",
    "\n",
    "print(f\"\\nðŸ“„ Random preview of {N} chunks with embeddings:\\n\")\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    chunk = kb.chunks[idx]\n",
    "    emb = document_embeddings[idx]\n",
    "    \n",
    "    print(f\"--- Sample {i+1} (Index {idx}) ---\")\n",
    "    print(f\"Page: {chunk['page']}\")\n",
    "    print(f\"Text (first 200 chars): {chunk['chunk'][:200]}...\")\n",
    "    print(f\"Embedding shape: {emb.shape}\")\n",
    "    print(f\"Embedding sample (first 10 values): {emb[:10]}\")\n",
    "    print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component 3: Retrieval System\n",
    "\n",
    "Build FAISS index for fast similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” COMPONENT 3: Retrieval System initialized (dim=384)\n",
      "\n",
      "ðŸ”¨ Building FAISS index...\n",
      "   Documents: 24\n",
      "   Embedding shape: (57, 384)\n",
      "âœ… Index built with 57 vectors\n",
      "\n",
      "âœ… Retrieval system ready to search!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Retrieval System\n",
    "retrieval = RetrievalSystem(dimension=384)\n",
    "\n",
    "# Build searchable index\n",
    "retrieval.build_index(document_embeddings, documents)\n",
    "\n",
    "print(\"\\nâœ… Retrieval system ready to search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Searching for top 3 relevant documents...\n",
      "âœ… Retrieved 3 documents\n",
      "Results structure:\n",
      "\n",
      "Result 0:\n",
      "{'rank': 1, 'document': {'page': 1, 'content': 'HPE Private Cloud AI 1.5 Administration Guide\\nHPE Private Cloud AI 1.5 Administration Guide\\nPart Number: 20-PCAI-UG-ED1\\nPublished: September 2025\\nEdition: 1.5'}, 'similarity': 0.4387816354426174, 'distance': 1.2790379524230957}\n",
      "--------------------------------------------------\n",
      "Result 1:\n",
      "{'rank': 2, 'document': {'page': 5, 'content': \"Scalability\\nScalability\\n: \\nHPE\\n \\nPrivate Cloud AI\\n's modular design allows organizations to start small and expand their AI capabilities as needed,\\nwithout major disruptions or reinvestments.\\nSimplified management\\nSimplified management\\n: \\nHPE\\n AI Essentials\\n provides comprehensive management tools and automation features, reducing the\\noperational complexity of running AI infrastructure.\\nEcosystem integration\\nEcosystem integration\\n: \\nHPE\\n \\nPrivate Cloud AI\\n is designed to work seamlessly with popular AI frameworks and development tools, such as\\nPyTorch, TensorFlow and JAX, allowing organizations to leverage their existing investments and skills.\\nExpert support\\nExpert support\\n: \\nHPE\\n and NVIDIA provide end-to-end support for \\nHPE\\n \\nPrivate Cloud AI\\n, including consulting services to help\\norganizations optimize their AI strategies and implementations. \\nHPE\\n offers comprehensive infrastructure solutions, while NVIDIA\\nprovides support for its AI frameworks and GPU technologies, enabling organizations to build and deploy powerful AI systems on-\\npremises.\\nExample Use Cases\\nExample Use Cases\\nHPE\\n \\nPrivate Cloud AI\\n offers organizations across various industries the ability to leverage the power of AI while maintaining enhanced\\nsecurity, data privacy, and customization capabilities. The following examples represent a \\nsubset\\nsubset\\n of potential use cases, demonstrating how\\ncustomers can develop tailored solutions using to address their specific needs.\\nSubtopics\\nSubtopics\\nPrivate Cloud AI Stack\\nPrivate Cloud AI Stack\\nDeveloper System\\nDeveloper System\\nHPE AI Essentials: Core Concepts\\nHPE AI Essentials: Core Concepts\\nSolution components\\nSolution components\\nSolution configurations\\nSolution configurations\\nPrivate Cloud AI User roles\\nPrivate Cloud AI User roles\\nSigning in to the HPE GreenLake platform and launching Private Cloud AI\\nSigning in to the HPE GreenLake platform and launching Private Cloud AI\\n \\n \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n \\nPrivate Cloud AI Stack\\nPrivate Cloud AI Stack\\nThe \\nPrivate Cloud AI\\n solution stack includes robust hardware, AI-native computing, storage, and networking components, all of which are\\naccessible and manageable through the GreenLake Cloud platform.\\nThe following diagram shows the \\nHPE\\n Private Cloud AI configurations, which include:\\nDeveloper System configuration\\nSmall configuration\\nMedium configuration\\nLarge configuration\\nFigure 1. \\nPrivate Cloud AI Configurations\\nHPE Private Cloud AI 1.5 Administration Guide\\n5\"}, 'similarity': 0.4371489200265147, 'distance': 1.2875499725341797}\n",
      "--------------------------------------------------\n",
      "Result 2:\n",
      "{'rank': 3, 'document': {'page': 16, 'content': 'Red Hat Enterprise Linux (RHEL)\\nRed Hat Enterprise Linux (RHEL)\\nHPE\\n sends an email receipt with the order\\ndetails and instructions to register the\\nproducts. The email is sent to the contact on\\nthe Purchase Order.\\n1\\n. \\nThe customer activates the purchased\\nproducts in the My \\nHPE\\n Software Center.\\n2\\n. \\nHPE\\n sends an email confirmation of\\nsuccessful registration within the My\\nHPE\\n Software Center.\\n3\\n. \\nThe customer completes the assignment\\nonline by logging into their account at\\nhttps://redhat.com\\nhttps://redhat.com\\n. After logging in, click\\nManage Accounts\\n > \\nSubscriptions\\n >\\nSubscription Inventory\\n > \\nSubscription\\nActivation\\n.\\n4\\n. \\nEnter the Subscription Activation\\nnumber that was provided in the \\nHPE\\nregistration.\\n5\\n. \\nService personnel log in to the worker\\nnode OS.\\n6\\n. \\nRun \\nsubscription-manager regist\\ner\\n.\\n7\\n. \\nThe customer enters their Red Hat login\\ncredentials.\\n8\\n. \\nRun \\nsubscription-manager attac\\nh --auto\\n or alternatively manually\\nspecify a pool.\\nHPE\\nHPE\\n AI Essentials\\n AI Essentials\\nHPE\\n sends an email receipt with the order\\ndetails and instructions to register the\\nproducts. The email is sent to the contact on\\nthe Purchase Order.\\nAfter completing the â€œ\\nHPE\\n Private Cloud AI\\nSetup wizardâ€ step for initial deployment:\\n1\\n. \\nHPE\\n TC launches the AI Essentials\\napplication.\\n2\\n. \\nThe first time the application is launched,\\nthe platform ID is displayed to the \\nHPE\\nTC.\\n3\\n. \\nThe \\nHPE\\n TC provides the customer with\\nthe platform ID either directly or via the\\nIPM.\\n4\\n. \\nThe customer goes to the \\nHPE\\n Software\\nCenter and entitles both the Ezmeral\\nvCPU and Ezmeral vGPU licenses.\\n5\\n. \\nHPE\\n sends an email confirmation to the\\ncustomer of successful registration\\nwithin the My \\nHPE\\n Software Center.\\n6\\n. \\nThe customer provides \\nHPE\\n the license\\nkey files.\\n7\\n. \\nThe installer drags/drops the file for the\\nEzmeral vCPU into the application. Then\\nthey open the AI Essentials application.\\n8\\n. \\nOnce in the application, they apply the\\nEzmeral vGPU license by clicking\\nAdministration\\n > \\nSettings\\n > \\nActivation\\nKey\\n > \\nUpload Activation Key\\n. Select the\\nfile for the Ezmeral vGPU license, and\\nupload it.\\nProduct\\nProduct\\nHow to receive the license information\\nHow to receive the license information\\nHow to apply the license information\\nHow to apply the license information\\nHPE Private Cloud AI 1.5 Administration Guide\\n16'}, 'similarity': 0.4357204857256046, 'distance': 1.2950493097305298}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Inspect retrieval output\n",
    "results = retrieval.search(semantic.encode_query(\"What are pcai core components\"), top_k=3)\n",
    "print(\"Results structure:\\n\")\n",
    "for i, r in enumerate(results):\n",
    "    print(f\"Result {i}:\")\n",
    "    print(r)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Complete RAG Pipeline\n",
    "\n",
    "Now let's ask a question and see all 5 components work together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "â“ QUESTION: What are pcai core tools\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Encoding question...\n",
      "[Step 2] Searching knowledge base...\n",
      "\n",
      "ðŸ”Ž Searching for top 3 relevant documents...\n",
      "âœ… Retrieved 3 documents\n",
      "\n",
      "ðŸ“š Retrieved Top 3 Chunks:\n",
      "  â€¢ Page 16 (similarity: 47.9%)\n",
      "    Text snippet: Red Hat Enterprise Linux (RHEL)\n",
      "Red Hat Enterprise Linux (RHEL)\n",
      "HPE\n",
      " sends an email receipt with the order\n",
      "details and instructions to register the\n",
      "products. The email is sent to the contact on\n",
      "the Pu...\n",
      "\n",
      "  â€¢ Page 20 (similarity: 47.7%)\n",
      "    Text snippet: Virtualization\n",
      "Virtualization\n",
      "VM Essentials\n",
      "Data Service Connectors\n",
      "Data Service Connectors\n",
      "HPE\n",
      "-DSC VM with equivalent KickStart Scripts\n",
      "Data Engineering Tools\n",
      "Data Engineering Tools\n",
      "Apache Airflow\n",
      "A...\n",
      "\n",
      "  â€¢ Page 21 (similarity: 47.3%)\n",
      "    Text snippet: HPE Private Cloud AI 1.5 Administration Guide\n",
      "21...\n",
      "\n",
      "[Step 3] Creating enriched context...\n",
      "âš¡ COMPONENT 4: Augmentation initialized\n",
      "\n",
      "âš¡ Creating enriched context with 3 documents...\n",
      "âœ… Enriched context created (3858 characters)\n",
      "[Step 4] Generating answer...\n",
      "ðŸ¤– COMPONENT 5: Generation initialized (simple mode)\n",
      "\n",
      "ðŸ¤– Generating answer...\n",
      "âœ… Answer generated\n",
      "\n",
      "======================================================================\n",
      "ðŸ’¬ ANSWER:\n",
      "======================================================================\n",
      "Based on 3 relevant scenes from Friends:\n",
      "\n",
      "1. Page 16 (relevance: 47.9%)\n",
      "   Red Hat Enterprise Linux (RHEL)\n",
      "Red Hat Enterprise Linux (RHEL)\n",
      "HPE\n",
      " sends an email receipt with the order\n",
      "details and instructions to register the\n",
      "products. The email is sent to the contact on\n",
      "the Pu...\n",
      "\n",
      "2. Page 20 (relevance: 47.7%)\n",
      "   Virtualization\n",
      "Virtualization\n",
      "VM Essentials\n",
      "Data Service Connectors\n",
      "Data Service Connectors\n",
      "HPE\n",
      "-DSC VM with equivalent KickStart Scripts\n",
      "Data Engineering Tools\n",
      "Data Engineering Tools\n",
      "Apache Airflow\n",
      "A...\n",
      "\n",
      "3. Page 21 (relevance: 47.3%)\n",
      "   HPE Private Cloud AI 1.5 Administration Guide\n",
      "21\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on 3 relevant scenes from Friends:\\n\\n1. Page 16 (relevance: 47.9%)\\n   Red Hat Enterprise Linux (RHEL)\\nRed Hat Enterprise Linux (RHEL)\\nHPE\\n sends an email receipt with the order\\ndetails and instructions to register the\\nproducts. The email is sent to the contact on\\nthe Pu...\\n\\n2. Page 20 (relevance: 47.7%)\\n   Virtualization\\nVirtualization\\nVM Essentials\\nData Service Connectors\\nData Service Connectors\\nHPE\\n-DSC VM with equivalent KickStart Scripts\\nData Engineering Tools\\nData Engineering Tools\\nApache Airflow\\nA...\\n\\n3. Page 21 (relevance: 47.3%)\\n   HPE Private Cloud AI 1.5 Administration Guide\\n21\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask_question(question, top_k=3):\n",
    "    \"\"\"Complete RAG pipeline for a question using PCAI PDF knowledge base\"\"\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(f\"â“ QUESTION: {question}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # COMPONENT 2: Encode query\n",
    "    print(\"\\n[Step 1] Encoding question...\")\n",
    "    query_embedding = semantic.encode_query(question)\n",
    "    \n",
    "    # COMPONENT 3: Retrieve relevant chunks\n",
    "    print(\"[Step 2] Searching knowledge base...\")\n",
    "    results = retrieval.search(query_embedding, top_k=top_k)\n",
    "    \n",
    "    print(f\"\\nðŸ“š Retrieved Top {top_k} Chunks:\")\n",
    "    for r in results:\n",
    "        doc_page = r['document']['page']\n",
    "        doc_text = r['document']['content']\n",
    "        print(f\"  â€¢ Page {doc_page} (similarity: {r['similarity']:.1%})\")\n",
    "        print(f\"    Text snippet: {doc_text[:200]}...\\n\")\n",
    "    \n",
    "    # COMPONENT 4: Augment with context\n",
    "    print(\"[Step 3] Creating enriched context...\")\n",
    "    augmentor = Augmentation()\n",
    "    enriched = augmentor.create_context(question, results)\n",
    "    \n",
    "    # COMPONENT 5: Generate answer\n",
    "    print(\"[Step 4] Generating answer...\")\n",
    "    generator = Generation()\n",
    "    answer = generator.generate(enriched, results)\n",
    "    \n",
    "    # Display answer\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ðŸ’¬ ANSWER:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(answer)\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "ask_question(\"What are pcai core tools\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try More Questions!\n",
    "\n",
    "Test the system with different queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "â“ QUESTION: What is pcai engineered system for?\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Encoding question...\n",
      "[Step 2] Searching knowledge base...\n",
      "\n",
      "ðŸ”Ž Searching for top 3 relevant documents...\n",
      "âœ… Retrieved 3 documents\n",
      "\n",
      "ðŸ“š Retrieved Top 3 Chunks:\n",
      "  â€¢ Page 21 (similarity: 46.9%)\n",
      "    Text snippet: HPE Private Cloud AI 1.5 Administration Guide\n",
      "21...\n",
      "\n",
      "  â€¢ Page 1 (similarity: 45.6%)\n",
      "    Text snippet: HPE Private Cloud AI 1.5 Administration Guide\n",
      "HPE Private Cloud AI 1.5 Administration Guide\n",
      "Part Number: 20-PCAI-UG-ED1\n",
      "Published: September 2025\n",
      "Edition: 1.5...\n",
      "\n",
      "  â€¢ Page 5 (similarity: 45.4%)\n",
      "    Text snippet: Scalability\n",
      "Scalability\n",
      ": \n",
      "HPE\n",
      " \n",
      "Private Cloud AI\n",
      "'s modular design allows organizations to start small and expand their AI capabilities as needed,\n",
      "without major disruptions or reinvestments.\n",
      "Simplifi...\n",
      "\n",
      "[Step 3] Creating enriched context...\n",
      "âš¡ COMPONENT 4: Augmentation initialized\n",
      "\n",
      "âš¡ Creating enriched context with 3 documents...\n",
      "âœ… Enriched context created (2904 characters)\n",
      "[Step 4] Generating answer...\n",
      "ðŸ¤– COMPONENT 5: Generation initialized (simple mode)\n",
      "\n",
      "ðŸ¤– Generating answer...\n",
      "âœ… Answer generated\n",
      "\n",
      "======================================================================\n",
      "ðŸ’¬ ANSWER:\n",
      "======================================================================\n",
      "Based on 3 relevant scenes from Friends:\n",
      "\n",
      "1. Page 21 (relevance: 46.9%)\n",
      "   HPE Private Cloud AI 1.5 Administration Guide\n",
      "21\n",
      "\n",
      "2. Page 1 (relevance: 45.6%)\n",
      "   HPE Private Cloud AI 1.5 Administration Guide\n",
      "HPE Private Cloud AI 1.5 Administration Guide\n",
      "Part Number: 20-PCAI-UG-ED1\n",
      "Published: September 2025\n",
      "Edition: 1.5\n",
      "\n",
      "3. Page 5 (relevance: 45.4%)\n",
      "   Scalability\n",
      "Scalability\n",
      ": \n",
      "HPE\n",
      " \n",
      "Private Cloud AI\n",
      "'s modular design allows organizations to start small and expand their AI capabilities as needed,\n",
      "without major disruptions or reinvestments.\n",
      "Simplifi...\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on 3 relevant scenes from Friends:\\n\\n1. Page 21 (relevance: 46.9%)\\n   HPE Private Cloud AI 1.5 Administration Guide\\n21\\n\\n2. Page 1 (relevance: 45.6%)\\n   HPE Private Cloud AI 1.5 Administration Guide\\nHPE Private Cloud AI 1.5 Administration Guide\\nPart Number: 20-PCAI-UG-ED1\\nPublished: September 2025\\nEdition: 1.5\\n\\n3. Page 5 (relevance: 45.4%)\\n   Scalability\\nScalability\\n: \\nHPE\\n \\nPrivate Cloud AI\\n's modular design allows organizations to start small and expand their AI capabilities as needed,\\nwithout major disruptions or reinvestments.\\nSimplifi...\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try these questions or write your own!\n",
    "\n",
    "ask_question(\"What is pcai engineered system for?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "â“ QUESTION: is spark used with livy\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Encoding question...\n",
      "[Step 2] Searching knowledge base...\n",
      "\n",
      "ðŸ”Ž Searching for top 3 relevant documents...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mask_question\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mis spark used with livy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mask_question\u001b[39m\u001b[34m(question, top_k)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# COMPONENT 3: Retrieve relevant chunks\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[Step 2] Searching knowledge base...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m results = \u001b[43mretrieval\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“š Retrieved Top \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtop_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Chunks:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/playground/at-2/pcai-at-2-rag/retrieval_system.py:77\u001b[39m, in \u001b[36mRetrievalSystem.search\u001b[39m\u001b[34m(self, query_embedding, top_k)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rank, (idx, distance) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(indices[\u001b[32m0\u001b[39m], distances[\u001b[32m0\u001b[39m]), \u001b[32m1\u001b[39m):\n\u001b[32m     73\u001b[39m     similarity = \u001b[32m1\u001b[39m / (\u001b[32m1\u001b[39m + \u001b[38;5;28mfloat\u001b[39m(distance))\n\u001b[32m     75\u001b[39m     results.append({\n\u001b[32m     76\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mrank\u001b[39m\u001b[33m'\u001b[39m: rank,\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdocument\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m     78\u001b[39m         \u001b[33m'\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m'\u001b[39m: similarity,\n\u001b[32m     79\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdistance\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(distance)\n\u001b[32m     80\u001b[39m     })\n\u001b[32m     82\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Retrieved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "ask_question(\"is spark used with livy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "â“ QUESTION: What is the hardware used\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Encoding question...\n",
      "[Step 2] Searching knowledge base...\n",
      "\n",
      "ðŸ”Ž Searching for top 3 relevant documents...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Your own question here!\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mask_question\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the hardware used\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mask_question\u001b[39m\u001b[34m(question, top_k)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# COMPONENT 3: Retrieve relevant chunks\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[Step 2] Searching knowledge base...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m results = \u001b[43mretrieval\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“š Retrieved Top \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtop_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Chunks:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/playground/at-2/pcai-at-2-rag/retrieval_system.py:77\u001b[39m, in \u001b[36mRetrievalSystem.search\u001b[39m\u001b[34m(self, query_embedding, top_k)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rank, (idx, distance) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(indices[\u001b[32m0\u001b[39m], distances[\u001b[32m0\u001b[39m]), \u001b[32m1\u001b[39m):\n\u001b[32m     73\u001b[39m     similarity = \u001b[32m1\u001b[39m / (\u001b[32m1\u001b[39m + \u001b[38;5;28mfloat\u001b[39m(distance))\n\u001b[32m     75\u001b[39m     results.append({\n\u001b[32m     76\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mrank\u001b[39m\u001b[33m'\u001b[39m: rank,\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdocument\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m     78\u001b[39m         \u001b[33m'\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m'\u001b[39m: similarity,\n\u001b[32m     79\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdistance\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(distance)\n\u001b[32m     80\u001b[39m     })\n\u001b[32m     82\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Retrieved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Your own question here!\n",
    "ask_question(\"What is the hardware used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Mode\n",
    "\n",
    "Keep asking questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive questioning\n",
    "while True:\n",
    "    user_question = input(\"\\nYour question (or 'quit' to stop): \").strip()\n",
    "    \n",
    "    if user_question.lower() in ['quit', 'exit', 'q']:\n",
    "        print(\"ðŸ‘‹ PDF RAG here to answer\")\n",
    "        break\n",
    "    \n",
    "    if user_question:\n",
    "        ask_question(user_question)\n",
    "    else:\n",
    "        print(\"Please enter a question!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
