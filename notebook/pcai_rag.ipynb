{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCAI PDF RAG System\n",
    "\n",
    "## Complete Implementation of 5 Required Components\n",
    "\n",
    "This notebook demonstrates a working Retrieval-Augmented Generation system using PDF File\n",
    "\n",
    "**Components Implemented:**\n",
    "1. Knowledge Base (PDF)\n",
    "2. Semantic Layer (sentence-transformers)\n",
    "3. Retrieval System (FAISS)\n",
    "4. Augmentation (context enrichment)\n",
    "5. Generation (answer synthesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import All Components\n",
    "\n",
    "Run this cell first to load all modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All components imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import our 5 components\n",
    "from knowledge_base import KnowledgeBase\n",
    "from semantic_layer import SemanticLayer\n",
    "from retrieval_system import RetrievalSystem\n",
    "from augmentation import Augmentation\n",
    "from generation import Generation\n",
    "print(\"âœ… All components imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component 1: Knowledge Base\n",
    "\n",
    "Load PCAI dataset from pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“š Knowledge Base initialized\n",
      "\n",
      "ðŸ“¥ Loading PDF: ../data/hpe-pcai.pdf\n",
      "âœ… Loaded 24 pages from PDF\n",
      "\n",
      " Creating chunks with LangChain RecursiveCharacterTextSplitter...\n",
      "âœ… Created 341 chunks\n",
      "\n",
      "ðŸ“Š Knowledge Base:\n",
      "   Pages: 24\n",
      "   Chunks: 341\n",
      "   Source: ../data/hpe-pcai.pdf\n",
      "   Chunk Size       : 200\n",
      "   Chunk Overlap    : 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize KB with PDF and chunk settings\n",
    "kb = KnowledgeBase(pdf_path=\"../data/hpe-pcai.pdf\", chunk_size=200, chunk_overlap=50)\n",
    "\n",
    "# Load PDF pages\n",
    "documents = kb.load_pdf_data()\n",
    "\n",
    "# Create sentence-preserving chunks\n",
    "chunks = kb.create_chunks()\n",
    "\n",
    "# Inspect stats\n",
    "stats = kb.get_stats()\n",
    "stats = kb.get_stats()\n",
    "print(f\"\\nðŸ“Š Knowledge Base:\")\n",
    "print(f\"   Pages: {stats['total_pages']}\")\n",
    "print(f\"   Chunks: {stats['total_chunks']}\")\n",
    "print(f\"   Source: {stats['source']}\")\n",
    "print(f\"   Chunk Size       : {kb.chunk_size}\")\n",
    "print(f\"   Chunk Overlap    : {kb.chunk_overlap}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component 2: Semantic Layer\n",
    "\n",
    "Convert text to numerical embeddings for semantic comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPONENT 2: Semantic Layer initializing...\n",
      "   Loading model: all-MiniLM-L6-v2\n",
      "   (First run downloads 22MB - takes 30 seconds)\n",
      "âœ… Model loaded! Embeddings dimension: 384\n",
      "\n",
      "ðŸ”„ Encoding 341 document chunks to embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c30ef47a224ffdb2d5038c16ad6ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings created: (341, 384)\n",
      "\n",
      "ðŸ“„ Random preview of 5 chunks with embeddings:\n",
      "\n",
      "--- Sample 1 (Index 59) ---\n",
      "Page: 4\n",
      "Text (first 200 chars): HPE\n",
      " \n",
      "Private Cloud AI\n",
      " helps organizations avoid the unpredictable costs\n",
      "associated with public cloud AI services, especially for large-scale or continuous workloads....\n",
      "Embedding shape: (384,)\n",
      "Embedding sample (first 10 values): [-0.06213689 -0.00925779  0.06471906  0.02861802  0.0600124   0.01544559\n",
      " -0.04650822 -0.04205861  0.07658074 -0.01001094]\n",
      "----------------------------------------------------------------------\n",
      "--- Sample 2 (Index 334) ---\n",
      "Page: 23\n",
      "Text (first 200 chars): Create an \n",
      "HPE\n",
      " GreenLake workspace\n",
      "Add Data Services Cloud Console to your workspace\n",
      "Add the Private Cloud AI service to Data Services Cloud Console\n",
      "Assign user roles\n",
      "After the \n",
      "Private Cloud AI...\n",
      "Embedding shape: (384,)\n",
      "Embedding sample (first 10 values): [-0.02285308 -0.09133134  0.02503943 -0.07249123 -0.00623796  0.01931972\n",
      "  0.00109714  0.05409911 -0.01556824  0.00978669]\n",
      "----------------------------------------------------------------------\n",
      "--- Sample 3 (Index 172) ---\n",
      "Page: 10\n",
      "Text (first 200 chars): Entity\n",
      "Entity\n",
      "Component Details\n",
      "Component Details\n",
      "Small, Medium and Large\n",
      "Small, Medium and Large\n",
      "Developer System\n",
      "Developer System\n",
      "Software\n",
      "Built on the\n",
      "â€¯\n",
      "HPE\n",
      "â€¯\n",
      "GreenLake Cloud Platform...\n",
      "Embedding shape: (384,)\n",
      "Embedding sample (first 10 values): [ 0.02360602 -0.00348063  0.06270351 -0.03298049  0.07116594 -0.03697946\n",
      " -0.01717662  0.03875603  0.02919465  0.06536224]\n",
      "----------------------------------------------------------------------\n",
      "--- Sample 4 (Index 91) ---\n",
      "Page: 6\n",
      "Text (first 200 chars): HPE\n",
      " Private Cloud AI configurations:\n",
      "Feature\n",
      "Feature\n",
      "Developer\n",
      "Developer\n",
      "System\n",
      "System\n",
      "Small\n",
      "Small\n",
      "Medium\n",
      "Medium\n",
      "Large\n",
      "Large\n",
      "Control Node Qty\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "Worker Node Qty\n",
      "1\n",
      "1 or 2\n",
      "2 or 4\n",
      "4 or 8...\n",
      "Embedding shape: (384,)\n",
      "Embedding sample (first 10 values): [ 0.01283068 -0.05031526  0.03003062  0.00929319  0.02896391  0.03547879\n",
      " -0.06051428  0.02177116 -0.04326529  0.02027894]\n",
      "----------------------------------------------------------------------\n",
      "--- Sample 5 (Index 3) ---\n",
      "Page: 2\n",
      "Text (first 200 chars): HPE\n",
      " \n",
      "Private Cloud AI\n",
      " AI\n",
      "solution. The guide describes the solution architecture, components, and configurations, with a focus on \n",
      "HPE\n",
      " AI Essentials - the core engine...\n",
      "Embedding shape: (384,)\n",
      "Embedding sample (first 10 values): [-0.07547244 -0.04306957  0.03779939 -0.00204324  0.07660634  0.02846383\n",
      " -0.0211562   0.01446917 -0.06304771 -0.0219387 ]\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Random Preview: Chunks & Embeddings\n",
    "# =========================\n",
    "\n",
    "# Number of random samples to preview\n",
    "N = 5\n",
    "\n",
    "# Ensure embeddings exist\n",
    "try:\n",
    "    document_embeddings\n",
    "except NameError:\n",
    "    # Encode chunks if not done yet\n",
    "    semantic = SemanticLayer()\n",
    "    document_embeddings = semantic.encode_documents(kb.chunks)\n",
    "\n",
    "# Random indices\n",
    "random_indices = random.sample(range(len(kb.chunks)), min(N, len(kb.chunks)))\n",
    "\n",
    "print(f\"\\nðŸ“„ Random preview of {N} chunks with embeddings:\\n\")\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    chunk = kb.chunks[idx]\n",
    "    emb = document_embeddings[idx]\n",
    "    \n",
    "    print(f\"--- Sample {i+1} (Index {idx}) ---\")\n",
    "    print(f\"Page: {chunk['page']}\")\n",
    "    print(f\"Text (first 200 chars): {chunk['chunk'][:200]}...\")\n",
    "    print(f\"Embedding shape: {emb.shape}\")\n",
    "    print(f\"Embedding sample (first 10 values): {emb[:10]}\")\n",
    "    print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component 3: Retrieval System\n",
    "\n",
    "Build FAISS index for fast similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” COMPONENT 3: Retrieval System initialized (dim=384)\n",
      "\n",
      "ðŸ”¨ Building FAISS index...\n",
      "   Documents: 341\n",
      "   Embedding shape: (341, 384)\n",
      "âœ… Index built with 341 vectors\n",
      "\n",
      "âœ… Retrieval system ready to search!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Retrieval System\n",
    "retrieval = RetrievalSystem(dimension=384)\n",
    "\n",
    "# Build searchable index\n",
    "retrieval.build_index(document_embeddings, kb.chunks)\n",
    "\n",
    "print(\"\\nâœ… Retrieval system ready to search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Searching for top 3 relevant documents...\n",
      "âœ… Retrieved 3 documents\n",
      "Results structure:\n",
      "\n",
      "Result 0:\n",
      "{'rank': 1, 'document': {'page': 7, 'chunk': 'HPE\\n AI Essentials Software.\\nCore Components\\nCore Components\\nOpen-Source Tools & Frameworks\\nOpen-Source Tools & Frameworks'}, 'similarity': 0.45020369059766646, 'distance': 1.2212167978286743}\n",
      "--------------------------------------------------\n",
      "Result 1:\n",
      "{'rank': 2, 'document': {'page': 4, 'chunk': 'HPE\\n AI Essentials\\n with NVIDIA NIMâ„¢\\nintegration, empowers organizations to swiftly build, deploy, and operate AI/ML models and GenAI applications. NVIDIA NIMâ„¢, part of'}, 'similarity': 0.44360095158939405, 'distance': 1.254278302192688}\n",
      "--------------------------------------------------\n",
      "Result 2:\n",
      "{'rank': 3, 'document': {'page': 2, 'chunk': 'troubleshooting procedures, and maintenance protocols.\\nPart Number: 20-PCAI-UG-ED1\\nPublished: September 2025\\nEdition: 1.5\\nÂ© Copyright 2025â€“ Hewlett Packard Enterprise Development LP\\nNotices\\nNotices'}, 'similarity': 0.4401994964625492, 'distance': 1.2716972827911377}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Inspect retrieval output\n",
    "results = retrieval.search(semantic.encode_query(\"What are pcai core components\"), top_k=3)\n",
    "print(\"Results structure:\\n\")\n",
    "for i, r in enumerate(results):\n",
    "    print(f\"Result {i}:\")\n",
    "    print(r)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Complete RAG Pipeline\n",
    "\n",
    "Now let's ask a question and see all 5 components work together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "â“ QUESTION: What are pcai core tools\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Encoding question...\n",
      "[Step 2] Searching knowledge base...\n",
      "\n",
      "ðŸ”Ž Searching for top 3 relevant documents...\n",
      "âœ… Retrieved 3 documents\n",
      "\n",
      "ðŸ“š Retrieved Top 3 Chunks:\n",
      "  â€¢ Page 7 (similarity: 50.2%)\n",
      "    Text snippet: HPE\n",
      " AI Essentials Software.\n",
      "Core Components\n",
      "Core Components\n",
      "Open-Source Tools & Frameworks\n",
      "Open-Source Tools & Frameworks...\n",
      "\n",
      "  â€¢ Page 8 (similarity: 47.6%)\n",
      "    Text snippet: AI assistants for the fastest path to inference with unparalleled performance.\n",
      "HPE\n",
      " AI Essentials Software\n",
      "â€¯\n",
      "currently includes the following pre-packaged NVIDIA NIM:...\n",
      "\n",
      "  â€¢ Page 4 (similarity: 47.3%)\n",
      "    Text snippet: HPE\n",
      " AI Essentials\n",
      " with NVIDIA NIMâ„¢\n",
      "integration, empowers organizations to swiftly build, deploy, and operate AI/ML models and GenAI applications. NVIDIA NIMâ„¢, part of...\n",
      "\n",
      "[Step 3] Creating enriched context...\n",
      "âš¡ COMPONENT 4: Augmentation initialized\n",
      "\n",
      "âš¡ Creating enriched context with 3 documents...\n",
      "âœ… Enriched context created (673 characters)\n",
      "[Step 4] Generating answer...\n",
      "ðŸ¤– COMPONENT 5: Generation initialized (Ollama: llama3.2:3b)\n",
      "âœ… Ollama connection successful\n",
      "\n",
      "ðŸ¤– Generating answer with LLM...\n",
      "âœ… Answer generated successfully with LLM\n",
      "\n",
      "======================================================================\n",
      "ðŸ’¬ ANSWER:\n",
      "======================================================================\n",
      "Based on the provided context, PCAI Core Tools are not explicitly mentioned in the text. However, it can be inferred that \"NVIDIA NIM\" (which is a pre-packaged tool) might be related to \"PCAi\" as part of HPE's AI Essentials Software.\n",
      "\n",
      "Since there is no direct mention of \"PCAi Core Tools,\" I'll provide an answer based on the context:\n",
      "\n",
      "It appears that PCAI refers to NVIDIA's Model Optimizing Tool, which is mentioned in the text as a pre-packaged tool within HPE's AI Essentials Software. The specific tools or frameworks included are not explicitly stated, but it can be inferred that they might include Open-Source Tools & Frameworks.\n",
      "\n",
      "If you're looking for more information on PCAi Core Tools, I recommend checking other sources or documentation related to NVIDIA's Model Optimizing Tool and its features.\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š SOURCES:\n",
      "======================================================================\n",
      "\n",
      "[1] Page 7 (Similarity: 50.2%)\n",
      "    Preview: HPE\n",
      " AI Essentials Software.\n",
      "Core Components\n",
      "Core Components\n",
      "Open-Source Tools & Frameworks\n",
      "Open-Source Tools & Frameworks\n",
      "\n",
      "[2] Page 8 (Similarity: 47.6%)\n",
      "    Preview: AI assistants for the fastest path to inference with unparalleled performance.\n",
      "HPE\n",
      " AI Essentials Software\n",
      "â€¯\n",
      "currently includes the following pre-pack...\n",
      "\n",
      "[3] Page 4 (Similarity: 47.3%)\n",
      "    Preview: HPE\n",
      " AI Essentials\n",
      " with NVIDIA NIMâ„¢\n",
      "integration, empowers organizations to swiftly build, deploy, and operate AI/ML models and GenAI applications. NV...\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, PCAI Core Tools are not explicitly mentioned in the text. However, it can be inferred that \"NVIDIA NIM\" (which is a pre-packaged tool) might be related to \"PCAi\" as part of HPE\\'s AI Essentials Software.\\n\\nSince there is no direct mention of \"PCAi Core Tools,\" I\\'ll provide an answer based on the context:\\n\\nIt appears that PCAI refers to NVIDIA\\'s Model Optimizing Tool, which is mentioned in the text as a pre-packaged tool within HPE\\'s AI Essentials Software. The specific tools or frameworks included are not explicitly stated, but it can be inferred that they might include Open-Source Tools & Frameworks.\\n\\nIf you\\'re looking for more information on PCAi Core Tools, I recommend checking other sources or documentation related to NVIDIA\\'s Model Optimizing Tool and its features.\\n\\n======================================================================\\nðŸ“š SOURCES:\\n======================================================================\\n\\n[1] Page 7 (Similarity: 50.2%)\\n    Preview: HPE\\n AI Essentials Software.\\nCore Components\\nCore Components\\nOpen-Source Tools & Frameworks\\nOpen-Source Tools & Frameworks\\n\\n[2] Page 8 (Similarity: 47.6%)\\n    Preview: AI assistants for the fastest path to inference with unparalleled performance.\\nHPE\\n AI Essentials Software\\n\\u202f\\ncurrently includes the following pre-pack...\\n\\n[3] Page 4 (Similarity: 47.3%)\\n    Preview: HPE\\n AI Essentials\\n with NVIDIA NIMâ„¢\\nintegration, empowers organizations to swiftly build, deploy, and operate AI/ML models and GenAI applications. NV...\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask_question(question, top_k=3):\n",
    "    \"\"\"Complete RAG pipeline for a question using PCAI PDF knowledge base\"\"\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(f\"â“ QUESTION: {question}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # COMPONENT 2: Encode query\n",
    "    print(\"\\n[Step 1] Encoding question...\")\n",
    "    query_embedding = semantic.encode_query(question)\n",
    "    \n",
    "    # COMPONENT 3: Retrieve relevant chunks\n",
    "    print(\"[Step 2] Searching knowledge base...\")\n",
    "    results = retrieval.search(query_embedding, top_k=top_k)\n",
    "    \n",
    "    print(f\"\\nðŸ“š Retrieved Top {top_k} Chunks:\")\n",
    "    for r in results:\n",
    "        doc_page = r['document']['page']\n",
    "        doc_text = r['document']['chunk']\n",
    "        print(f\"  â€¢ Page {doc_page} (similarity: {r['similarity']:.1%})\")\n",
    "        print(f\"    Text snippet: {doc_text[:200]}...\\n\")\n",
    "    \n",
    "    # COMPONENT 4: Augment with context\n",
    "    print(\"[Step 3] Creating enriched context...\")\n",
    "    augmentor = Augmentation()\n",
    "    enriched = augmentor.create_context(question, results)\n",
    "    \n",
    "    # COMPONENT 5: Generate answer\n",
    "    print(\"[Step 4] Generating answer...\")\n",
    "    generator = Generation(model_name='llama3.2:3b', use_llm=True)\n",
    "    answer = generator.generate(enriched, results)\n",
    "    \n",
    "    # Display answer\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ðŸ’¬ ANSWER:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(answer)\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "ask_question(\"What are pcai core tools\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try More Questions!\n",
    "\n",
    "Test the system with different queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "â“ QUESTION: What is pcai engineered system for?\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Encoding question...\n",
      "[Step 2] Searching knowledge base...\n",
      "\n",
      "ðŸ”Ž Searching for top 3 relevant documents...\n",
      "âœ… Retrieved 3 documents\n",
      "\n",
      "ðŸ“š Retrieved Top 3 Chunks:\n",
      "  â€¢ Page 5 (similarity: 48.1%)\n",
      "    Text snippet: HPE\n",
      " offers comprehensive infrastructure solutions, while NVIDIA\n",
      "provides support for its AI frameworks and GPU technologies, enabling organizations to build and deploy powerful AI systems on-...\n",
      "\n",
      "  â€¢ Page 8 (similarity: 47.8%)\n",
      "    Text snippet: NVIDIA Blueprints\n",
      "NVIDIA Blueprints\n",
      ".\n",
      "You can use Blueprints to jumpstart or accelerate the development and deployment of AI use cases. Blueprints cover a wide range of use...\n",
      "\n",
      "  â€¢ Page 4 (similarity: 47.4%)\n",
      "    Text snippet: HPE\n",
      " AI Essentials\n",
      " with NVIDIA NIMâ„¢\n",
      "integration, empowers organizations to swiftly build, deploy, and operate AI/ML models and GenAI applications. NVIDIA NIMâ„¢, part of...\n",
      "\n",
      "[Step 3] Creating enriched context...\n",
      "âš¡ COMPONENT 4: Augmentation initialized\n",
      "\n",
      "âš¡ Creating enriched context with 3 documents...\n",
      "âœ… Enriched context created (760 characters)\n",
      "[Step 4] Generating answer...\n",
      "ðŸ¤– COMPONENT 5: Generation initialized (Ollama: llama3.2:3b)\n",
      "âœ… Ollama connection successful\n",
      "\n",
      "ðŸ¤– Generating answer with LLM...\n",
      "âœ… Answer generated successfully with LLM\n",
      "\n",
      "======================================================================\n",
      "ðŸ’¬ ANSWER:\n",
      "======================================================================\n",
      "Based on the provided context, it appears that PCAI (not explicitly mentioned in the PDF) is not a clear topic. However, I can infer that PCAI might be related to AI systems.\n",
      "\n",
      "According to Page 4, HPE offers \"AI Essentials\" with NVIDIA NIM integration, which enables organizations to build, deploy, and operate AI/ML models and GenAI applications.\n",
      "\n",
      "Considering this information, it's possible that PCAI is an engineered system for building and deploying AI use cases. However, without explicit mention of PCAI in the PDF, I couldn't determine its exact purpose or definition.\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š SOURCES:\n",
      "======================================================================\n",
      "\n",
      "[1] Page 5 (Similarity: 48.1%)\n",
      "    Preview: HPE\n",
      " offers comprehensive infrastructure solutions, while NVIDIA\n",
      "provides support for its AI frameworks and GPU technologies, enabling organizations t...\n",
      "\n",
      "[2] Page 8 (Similarity: 47.8%)\n",
      "    Preview: NVIDIA Blueprints\n",
      "NVIDIA Blueprints\n",
      ".\n",
      "You can use Blueprints to jumpstart or accelerate the development and deployment of AI use cases. Blueprints cov...\n",
      "\n",
      "[3] Page 4 (Similarity: 47.4%)\n",
      "    Preview: HPE\n",
      " AI Essentials\n",
      " with NVIDIA NIMâ„¢\n",
      "integration, empowers organizations to swiftly build, deploy, and operate AI/ML models and GenAI applications. NV...\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, it appears that PCAI (not explicitly mentioned in the PDF) is not a clear topic. However, I can infer that PCAI might be related to AI systems.\\n\\nAccording to Page 4, HPE offers \"AI Essentials\" with NVIDIA NIM integration, which enables organizations to build, deploy, and operate AI/ML models and GenAI applications.\\n\\nConsidering this information, it\\'s possible that PCAI is an engineered system for building and deploying AI use cases. However, without explicit mention of PCAI in the PDF, I couldn\\'t determine its exact purpose or definition.\\n\\n======================================================================\\nðŸ“š SOURCES:\\n======================================================================\\n\\n[1] Page 5 (Similarity: 48.1%)\\n    Preview: HPE\\n offers comprehensive infrastructure solutions, while NVIDIA\\nprovides support for its AI frameworks and GPU technologies, enabling organizations t...\\n\\n[2] Page 8 (Similarity: 47.8%)\\n    Preview: NVIDIA Blueprints\\nNVIDIA Blueprints\\n.\\nYou can use Blueprints to jumpstart or accelerate the development and deployment of AI use cases. Blueprints cov...\\n\\n[3] Page 4 (Similarity: 47.4%)\\n    Preview: HPE\\n AI Essentials\\n with NVIDIA NIMâ„¢\\nintegration, empowers organizations to swiftly build, deploy, and operate AI/ML models and GenAI applications. NV...\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try these questions or write your own!\n",
    "\n",
    "ask_question(\"What is pcai engineered system for?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "â“ QUESTION: does HPE offer supportf or AI products on delivery\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Encoding question...\n",
      "[Step 2] Searching knowledge base...\n",
      "\n",
      "ðŸ”Ž Searching for top 3 relevant documents...\n",
      "âœ… Retrieved 3 documents\n",
      "\n",
      "ðŸ“š Retrieved Top 3 Chunks:\n",
      "  â€¢ Page 4 (similarity: 60.1%)\n",
      "    Text snippet: Hewlett Packard Enterprise\n",
      " features explicit support for \n",
      "HPE\n",
      " and NVIDIA AI software, and is...\n",
      "\n",
      "  â€¢ Page 7 (similarity: 58.3%)\n",
      "    Text snippet: production. \n",
      "HPE\n",
      " AI Essentials Software provides a ready-to-run set of AI and open-source tools to build end-to-end GenAI solutions.\n",
      "From novice to expert, \n",
      "HPE...\n",
      "\n",
      "  â€¢ Page 7 (similarity: 58.2%)\n",
      "    Text snippet: HPE\n",
      " AI Essentials Software is part of the \n",
      "HPE\n",
      " Private Cloud AI software and data foundation layer that accelerates the time from AI pilot to\n",
      "production. \n",
      "HPE...\n",
      "\n",
      "[Step 3] Creating enriched context...\n",
      "âš¡ COMPONENT 4: Augmentation initialized\n",
      "\n",
      "âš¡ Creating enriched context with 3 documents...\n",
      "âœ… Enriched context created (658 characters)\n",
      "[Step 4] Generating answer...\n",
      "ðŸ¤– COMPONENT 5: Generation initialized (Ollama: llama3.2:3b)\n",
      "âœ… Ollama connection successful\n",
      "\n",
      "ðŸ¤– Generating answer with LLM...\n",
      "âœ… Answer generated successfully with LLM\n",
      "\n",
      "======================================================================\n",
      "ðŸ’¬ ANSWER:\n",
      "======================================================================\n",
      "Yes, HPE offers support for AI products on delivery. The relevant text states:\n",
      "\n",
      "\"Hewlett Packard Enterprise features explicit support for HPE and NVIDIA AI software...\"\n",
      "\n",
      "This indicates that HPE provides support for its own AI software, as well as software from NVIDIA. Additionally, the text mentions that HPE's AI Essentials Software is part of a private cloud AI solution that includes \"explicit support\" for AI products.\n",
      "\n",
      "Therefore, it can be concluded that HPE does offer support for AI products on delivery.\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š SOURCES:\n",
      "======================================================================\n",
      "\n",
      "[1] Page 4 (Similarity: 60.1%)\n",
      "    Preview: Hewlett Packard Enterprise\n",
      " features explicit support for \n",
      "HPE\n",
      " and NVIDIA AI software, and is\n",
      "\n",
      "[2] Page 7 (Similarity: 58.3%)\n",
      "    Preview: production. \n",
      "HPE\n",
      " AI Essentials Software provides a ready-to-run set of AI and open-source tools to build end-to-end GenAI solutions.\n",
      "From novice to e...\n",
      "\n",
      "[3] Page 7 (Similarity: 58.2%)\n",
      "    Preview: HPE\n",
      " AI Essentials Software is part of the \n",
      "HPE\n",
      " Private Cloud AI software and data foundation layer that accelerates the time from AI pilot to\n",
      "produc...\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, HPE offers support for AI products on delivery. The relevant text states:\\n\\n\"Hewlett Packard Enterprise features explicit support for HPE and NVIDIA AI software...\"\\n\\nThis indicates that HPE provides support for its own AI software, as well as software from NVIDIA. Additionally, the text mentions that HPE\\'s AI Essentials Software is part of a private cloud AI solution that includes \"explicit support\" for AI products.\\n\\nTherefore, it can be concluded that HPE does offer support for AI products on delivery.\\n\\n======================================================================\\nðŸ“š SOURCES:\\n======================================================================\\n\\n[1] Page 4 (Similarity: 60.1%)\\n    Preview: Hewlett Packard Enterprise\\n features explicit support for \\nHPE\\n and NVIDIA AI software, and is\\n\\n[2] Page 7 (Similarity: 58.3%)\\n    Preview: production. \\nHPE\\n AI Essentials Software provides a ready-to-run set of AI and open-source tools to build end-to-end GenAI solutions.\\nFrom novice to e...\\n\\n[3] Page 7 (Similarity: 58.2%)\\n    Preview: HPE\\n AI Essentials Software is part of the \\nHPE\\n Private Cloud AI software and data foundation layer that accelerates the time from AI pilot to\\nproduc...\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_question(\"does HPE offer supportf or AI products on delivery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "â“ QUESTION: Who is customer support engineer, doe they helo with AI platform\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Encoding question...\n",
      "[Step 2] Searching knowledge base...\n",
      "\n",
      "ðŸ”Ž Searching for top 3 relevant documents...\n",
      "âœ… Retrieved 3 documents\n",
      "\n",
      "ðŸ“š Retrieved Top 3 Chunks:\n",
      "  â€¢ Page 5 (similarity: 49.4%)\n",
      "    Text snippet: Private Cloud AI Stack\n",
      "Private Cloud AI Stack\n",
      "Developer System\n",
      "Developer System\n",
      "HPE AI Essentials: Core Concepts\n",
      "HPE AI Essentials: Core Concepts\n",
      "Solution components\n",
      "Solution components...\n",
      "\n",
      "  â€¢ Page 23 (similarity: 48.8%)\n",
      "    Text snippet: Maintain self-service access to various AI tools, frameworks, and development environments, such as \n",
      "HPE\n",
      " AI Essentials Software...\n",
      "\n",
      "  â€¢ Page 4 (similarity: 48.6%)\n",
      "    Text snippet: support, trusted AI services for data and model compliance, and features ensuring AI pipeline compliance, explainability, and reproducibility\n",
      "throughout the AI lifecycle, \n",
      "HPE\n",
      " AI Essentials...\n",
      "\n",
      "[Step 3] Creating enriched context...\n",
      "âš¡ COMPONENT 4: Augmentation initialized\n",
      "\n",
      "âš¡ Creating enriched context with 3 documents...\n",
      "âœ… Enriched context created (761 characters)\n",
      "[Step 4] Generating answer...\n",
      "ðŸ¤– COMPONENT 5: Generation initialized (Ollama: llama3.2:3b)\n",
      "âœ… Ollama connection successful\n",
      "\n",
      "ðŸ¤– Generating answer with LLM...\n",
      "âœ… Answer generated successfully with LLM\n",
      "\n",
      "======================================================================\n",
      "ðŸ’¬ ANSWER:\n",
      "======================================================================\n",
      "Based on the provided context, a Customer Support Engineer may not necessarily be directly involved with an AI platform.\n",
      "\n",
      "However, they might be responsible for supporting customers who are using HPE AI Essentials Software, which includes features such as maintaining self-service access to various AI tools, frameworks, and development environments (Page 23). Additionally, they may provide support related to trusted AI services, data and model compliance, explainability, and reproducibility throughout the AI lifecycle (Page 4).\n",
      "\n",
      "The connection to an AI platform is not explicitly stated in the provided context. It seems that Customer Support Engineers might be more focused on supporting customers using HPE AI Essentials Software, rather than specifically working with AI platforms.\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š SOURCES:\n",
      "======================================================================\n",
      "\n",
      "[1] Page 5 (Similarity: 49.4%)\n",
      "    Preview: Private Cloud AI Stack\n",
      "Private Cloud AI Stack\n",
      "Developer System\n",
      "Developer System\n",
      "HPE AI Essentials: Core Concepts\n",
      "HPE AI Essentials: Core Concepts\n",
      "Solu...\n",
      "\n",
      "[2] Page 23 (Similarity: 48.8%)\n",
      "    Preview: Maintain self-service access to various AI tools, frameworks, and development environments, such as \n",
      "HPE\n",
      " AI Essentials Software\n",
      "\n",
      "[3] Page 4 (Similarity: 48.6%)\n",
      "    Preview: support, trusted AI services for data and model compliance, and features ensuring AI pipeline compliance, explainability, and reproducibility\n",
      "througho...\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, a Customer Support Engineer may not necessarily be directly involved with an AI platform.\\n\\nHowever, they might be responsible for supporting customers who are using HPE AI Essentials Software, which includes features such as maintaining self-service access to various AI tools, frameworks, and development environments (Page 23). Additionally, they may provide support related to trusted AI services, data and model compliance, explainability, and reproducibility throughout the AI lifecycle (Page 4).\\n\\nThe connection to an AI platform is not explicitly stated in the provided context. It seems that Customer Support Engineers might be more focused on supporting customers using HPE AI Essentials Software, rather than specifically working with AI platforms.\\n\\n======================================================================\\nðŸ“š SOURCES:\\n======================================================================\\n\\n[1] Page 5 (Similarity: 49.4%)\\n    Preview: Private Cloud AI Stack\\nPrivate Cloud AI Stack\\nDeveloper System\\nDeveloper System\\nHPE AI Essentials: Core Concepts\\nHPE AI Essentials: Core Concepts\\nSolu...\\n\\n[2] Page 23 (Similarity: 48.8%)\\n    Preview: Maintain self-service access to various AI tools, frameworks, and development environments, such as \\nHPE\\n AI Essentials Software\\n\\n[3] Page 4 (Similarity: 48.6%)\\n    Preview: support, trusted AI services for data and model compliance, and features ensuring AI pipeline compliance, explainability, and reproducibility\\nthrougho...\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your own question here!\n",
    "ask_question(\"Who is customer support engineer, doe they helo with AI platform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Mode\n",
    "\n",
    "Keep asking questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your question (or 'quit' to stop):  what is the optimum environment recommended\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "â“ QUESTION: what is the optimum environment recommended\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Encoding question...\n",
      "[Step 2] Searching knowledge base...\n",
      "\n",
      "ðŸ”Ž Searching for top 3 relevant documents...\n",
      "âœ… Retrieved 3 documents\n",
      "\n",
      "ðŸ“š Retrieved Top 3 Chunks:\n",
      "  â€¢ Page 11 (similarity: 78.0%)\n",
      "    Text snippet: Optimum environment\n",
      "Optimum environment...\n",
      "\n",
      "  â€¢ Page 11 (similarity: 52.4%)\n",
      "    Text snippet: Optimum environment\n",
      "Optimum environment\n",
      "To provide optimum performance with minimum maintenance for your rack environment, you must meet specific requirements for airflow,...\n",
      "\n",
      "  â€¢ Page 3 (similarity: 49.0%)\n",
      "    Text snippet: Solution components\n",
      "Optimum environment\n",
      "Airflow requirements\n",
      "Power requirements\n",
      "Space requirements\n",
      "Temperature requirements\n",
      "Firewall and port requirements\n",
      "Networking requirements...\n",
      "\n",
      "[Step 3] Creating enriched context...\n",
      "âš¡ COMPONENT 4: Augmentation initialized\n",
      "\n",
      "âš¡ Creating enriched context with 3 documents...\n",
      "âœ… Enriched context created (626 characters)\n",
      "[Step 4] Generating answer...\n",
      "ðŸ¤– COMPONENT 5: Generation initialized (Ollama: llama3.2:3b)\n",
      "âœ… Ollama connection successful\n",
      "\n",
      "ðŸ¤– Generating answer with LLM...\n",
      "âœ… Answer generated successfully with LLM\n",
      "\n",
      "======================================================================\n",
      "ðŸ’¬ ANSWER:\n",
      "======================================================================\n",
      "Based on the provided context, the optimum environment recommended for a rack environment is one that meets specific requirements for:\n",
      "\n",
      "1. Airflow\n",
      "2. Power\n",
      "3. Space\n",
      "4. Temperature\n",
      "5. Firewall and port requirements\n",
      "6. Networking requirements\n",
      "\n",
      "To provide optimum performance with minimum maintenance, these requirements must be met.\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š SOURCES:\n",
      "======================================================================\n",
      "\n",
      "[1] Page 11 (Similarity: 78.0%)\n",
      "    Preview: Optimum environment\n",
      "Optimum environment\n",
      "\n",
      "[2] Page 11 (Similarity: 52.4%)\n",
      "    Preview: Optimum environment\n",
      "Optimum environment\n",
      "To provide optimum performance with minimum maintenance for your rack environment, you must meet specific requ...\n",
      "\n",
      "[3] Page 3 (Similarity: 49.0%)\n",
      "    Preview: Solution components\n",
      "Optimum environment\n",
      "Airflow requirements\n",
      "Power requirements\n",
      "Space requirements\n",
      "Temperature requirements\n",
      "Firewall and port requirem...\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your question (or 'quit' to stop):  do i need a spearate nvidia subscription or the pcai comes with it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "â“ QUESTION: do i need a spearate nvidia subscription or the pcai comes with it?\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Encoding question...\n",
      "[Step 2] Searching knowledge base...\n",
      "\n",
      "ðŸ”Ž Searching for top 3 relevant documents...\n",
      "âœ… Retrieved 3 documents\n",
      "\n",
      "ðŸ“š Retrieved Top 3 Chunks:\n",
      "  â€¢ Page 17 (similarity: 57.6%)\n",
      "    Text snippet: Activating the NVIDIA software subscription\n",
      "The following table describes adding the NVIDIA license information for various Private Cloud AI configurations....\n",
      "\n",
      "  â€¢ Page 17 (similarity: 54.7%)\n",
      "    Text snippet: subscription\n",
      ".\n",
      "See \n",
      "Activating the NVIDIA software\n",
      "subscription\n",
      ".\n",
      "HPE\n",
      "HPE\n",
      " Private Cloud AI Platform\n",
      " Private Cloud AI Platform\n",
      "The subscription is provided through\n",
      "GreenLake Cloud....\n",
      "\n",
      "  â€¢ Page 18 (similarity: 54.1%)\n",
      "    Text snippet: 4\n",
      ". \n",
      "The customer must register on the\n",
      "NVIDIA website to receive NVIDIA\n",
      "support.\n",
      "5\n",
      ". \n",
      "No additional on-prem licensing is\n",
      "required.\n",
      "Developer and Large Configuration (NVIDIA...\n",
      "\n",
      "[Step 3] Creating enriched context...\n",
      "âš¡ COMPONENT 4: Augmentation initialized\n",
      "\n",
      "âš¡ Creating enriched context with 3 documents...\n",
      "âœ… Enriched context created (772 characters)\n",
      "[Step 4] Generating answer...\n",
      "ðŸ¤– COMPONENT 5: Generation initialized (Ollama: llama3.2:3b)\n",
      "âœ… Ollama connection successful\n",
      "\n",
      "ðŸ¤– Generating answer with LLM...\n",
      "âœ… Answer generated successfully with LLM\n",
      "\n",
      "======================================================================\n",
      "ðŸ’¬ ANSWER:\n",
      "======================================================================\n",
      "Based on the provided context, it appears that a separate NVIDIA subscription may not be required if you are purchasing the Private Cloud AI Platform through GreenLake Cloud.\n",
      "\n",
      "On page 17, it states:\n",
      "\n",
      "\"The subscription is provided through GreenLake Cloud.\"\n",
      "\n",
      "This suggests that the subscription is included with the purchase of the Private Cloud AI Platform through GreenLake Cloud. Additionally, on page 18, it mentions that \"No additional on-prem licensing is required\", which implies that the NVIDIA software license is already included in the configuration.\n",
      "\n",
      "Therefore, unless you have specific requirements or plans to use NVIDIA's software outside of the Private Cloud AI Platform, it seems likely that the subscription is included with your purchase and a separate subscription may not be necessary.\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š SOURCES:\n",
      "======================================================================\n",
      "\n",
      "[1] Page 17 (Similarity: 57.6%)\n",
      "    Preview: Activating the NVIDIA software subscription\n",
      "The following table describes adding the NVIDIA license information for various Private Cloud AI configura...\n",
      "\n",
      "[2] Page 17 (Similarity: 54.7%)\n",
      "    Preview: subscription\n",
      ".\n",
      "See \n",
      "Activating the NVIDIA software\n",
      "subscription\n",
      ".\n",
      "HPE\n",
      "HPE\n",
      " Private Cloud AI Platform\n",
      " Private Cloud AI Platform\n",
      "The subscription is pr...\n",
      "\n",
      "[3] Page 18 (Similarity: 54.1%)\n",
      "    Preview: 4\n",
      ". \n",
      "The customer must register on the\n",
      "NVIDIA website to receive NVIDIA\n",
      "support.\n",
      "5\n",
      ". \n",
      "No additional on-prem licensing is\n",
      "required.\n",
      "Developer and Large...\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your question (or 'quit' to stop):  what are the licensing reqs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "â“ QUESTION: what are the licensing reqs\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Encoding question...\n",
      "[Step 2] Searching knowledge base...\n",
      "\n",
      "ðŸ”Ž Searching for top 3 relevant documents...\n",
      "âœ… Retrieved 3 documents\n",
      "\n",
      "ðŸ“š Retrieved Top 3 Chunks:\n",
      "  â€¢ Page 15 (similarity: 53.9%)\n",
      "    Text snippet: Licensing requirements\n",
      "Licensing requirements\n",
      "The following table describes how you receive and apply license information for the software components that make up the \n",
      "HPE...\n",
      "\n",
      "  â€¢ Page 11 (similarity: 49.0%)\n",
      "    Text snippet: Subtopics\n",
      "Optimum environment\n",
      "Optimum environment\n",
      "Licensing requirements\n",
      "Licensing requirements\n",
      "Activating the NVIDIA software subscription\n",
      "Activating the NVIDIA software subscription...\n",
      "\n",
      "  â€¢ Page 16 (similarity: 47.8%)\n",
      "    Text snippet: Product\n",
      "How to receive the license information\n",
      "How to receive the license information\n",
      "How to apply the license information\n",
      "How to apply the license information...\n",
      "\n",
      "[Step 3] Creating enriched context...\n",
      "âš¡ COMPONENT 4: Augmentation initialized\n",
      "\n",
      "âš¡ Creating enriched context with 3 documents...\n",
      "âœ… Enriched context created (736 characters)\n",
      "[Step 4] Generating answer...\n",
      "ðŸ¤– COMPONENT 5: Generation initialized (Ollama: llama3.2:3b)\n",
      "âœ… Ollama connection successful\n",
      "\n",
      "ðŸ¤– Generating answer with LLM...\n",
      "âœ… Answer generated successfully with LLM\n",
      "\n",
      "======================================================================\n",
      "ðŸ’¬ ANSWER:\n",
      "======================================================================\n",
      "Unfortunately, the provided text does not explicitly state the licensing requirements. However, it does provide some relevant information on how to receive and apply license information for software components.\n",
      "\n",
      "From the context, we can infer that the licensing requirements are related to activating the NVIDIA software subscription, as mentioned on pages 11 and 16. Additionally, there is a table on page 15 that describes how to receive and apply license information, but its content is not explicitly stated in the provided text.\n",
      "\n",
      "To answer your question more accurately, I would need more specific information about what licensing requirements you are referring to (e.g., hardware, software, etc.). If you could provide more context or clarify which licensing requirements you are interested in, I would be happy to try and assist you further.\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š SOURCES:\n",
      "======================================================================\n",
      "\n",
      "[1] Page 15 (Similarity: 53.9%)\n",
      "    Preview: Licensing requirements\n",
      "Licensing requirements\n",
      "The following table describes how you receive and apply license information for the software components ...\n",
      "\n",
      "[2] Page 11 (Similarity: 49.0%)\n",
      "    Preview: Subtopics\n",
      "Optimum environment\n",
      "Optimum environment\n",
      "Licensing requirements\n",
      "Licensing requirements\n",
      "Activating the NVIDIA software subscription\n",
      "Activating...\n",
      "\n",
      "[3] Page 16 (Similarity: 47.8%)\n",
      "    Preview: Product\n",
      "How to receive the license information\n",
      "How to receive the license information\n",
      "How to apply the license information\n",
      "How to apply the license in...\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Interactive questioning\n",
    "while True:\n",
    "    user_question = input(\"\\nYour question (or 'quit' to stop): \").strip()\n",
    "    \n",
    "    if user_question.lower() in ['quit', 'exit', 'q']:\n",
    "        print(\"ðŸ‘‹ PDF RAG here to answer\")\n",
    "        break\n",
    "    \n",
    "    if user_question:\n",
    "        ask_question(user_question)\n",
    "    else:\n",
    "        print(\"Please enter a question!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
